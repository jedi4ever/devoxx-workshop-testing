{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : we are pinning the inspect_ai due to a recent breaking change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q openai anthropic ipywidgets colorama\n",
    "import os\n",
    "os.environ['XDG_RUNTIME_DIR']=\"/tmp\"\n",
    "os.environ['INSPECT_EVAL_MODEL'] = \"openai/gpt-4o-mini\"\n",
    "\n",
    "from helpers.reporter.pretty import pretty_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a shell one with tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add all the models we want to test across"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspect_ai.agent import Agent, AgentState, agent, as_solver, as_tool\n",
    "from inspect_ai.model import ChatMessageSystem, get_model\n",
    "from inspect_ai.tool import web_browser\n",
    "\n",
    "@agent\n",
    "def web_surfer() -> Agent:\n",
    "    async def execute(state: AgentState) -> AgentState:\n",
    "        \"\"\"Web research assistant.\"\"\"\n",
    "      \n",
    "        # some general guidance for the agent\n",
    "        state.messages.append(\n",
    "            ChatMessageSystem(\n",
    "                content=\"You are an expert at using a \" + \n",
    "                \"web browser to answer questions.\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # run a tool loop w/ the web_browser \n",
    "        messages, output = await get_model().generate_loop(\n",
    "            state.messages, tools=web_browser(interactive=False),\n",
    "        )\n",
    "\n",
    "        # update and return state\n",
    "        state.output = output\n",
    "        state.messages.extend(messages)\n",
    "        return state\n",
    "\n",
    "    return execute\n",
    "\n",
    "from inspect_ai.agent import react\n",
    "from inspect_ai.tool import web_browser\n",
    "\n",
    "\n",
    "from inspect_ai.solver import generate, use_tools\n",
    "from inspect_ai import Task, eval, task\n",
    "from inspect_ai.dataset import json_dataset\n",
    "from inspect_ai.scorer import includes\n",
    "from inspect_ai.dataset import Sample\n",
    "\n",
    "@task\n",
    "def custom_agent():\n",
    "\n",
    "    dataset = [\n",
    "     Sample(input=\"Where does patrick debois live ? Use wikipedia\", target=\"Belgium\")\n",
    "    ]\n",
    " \n",
    "    task = Task(\n",
    "        dataset=dataset,\n",
    "        solver=web_surfer(),\n",
    "        scorer=includes(),\n",
    "        sandbox=\"docker\"\n",
    "    )\n",
    "    return task\n",
    "\n",
    "results = eval(custom_agent,log_level=\"info\",display=\"none\")\n",
    "print(pretty_results(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspect_ai.agent import react\n",
    "from inspect_ai.tool import web_browser\n",
    "from inspect_ai.solver import generate, use_tools\n",
    "from inspect_ai import Task, eval, task\n",
    "from inspect_ai.dataset import json_dataset\n",
    "from inspect_ai.scorer import includes\n",
    "from inspect_ai.dataset import Sample\n",
    "\n",
    "\n",
    "web_surfer = react(\n",
    "    name=\"web_surfer\",\n",
    "    description=\"Web research assistant\",\n",
    "    prompt=\"You are a tenacious web researcher that is expert \"\n",
    "           + \"at using a web browser to answer questions.\",\n",
    "    tools=web_browser()   \n",
    ")\n",
    "\n",
    "from inspect_ai.agent import handoff\n",
    "from inspect_ai.dataset import Sample\n",
    "\n",
    "supervisor = react(\n",
    "    prompt=\"You are an agent that can answer addition \" \n",
    "            + \"problems and do web research.\",\n",
    "    tools=[ handoff(web_surfer)]\n",
    ")\n",
    "\n",
    "agent_handoff = Task(\n",
    "    dataset=[\n",
    "        Sample(input=\"Please add 1+1 then tell me what \" \n",
    "                     + \"movies were popular in 2020\")\n",
    "    ],\n",
    "    solver=supervisor,\n",
    "    sandbox=\"docker\",\n",
    ")\n",
    "\n",
    "results = eval(agent_handoff, log_level=\"info\", display=\"none\")\n",
    "print(pretty_results(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspect_ai.agent import react\n",
    "from inspect_ai.tool import web_browser\n",
    "from inspect_ai.solver import generate, use_tools\n",
    "from inspect_ai import Task, eval, task\n",
    "from inspect_ai.dataset import json_dataset\n",
    "from inspect_ai.scorer import includes\n",
    "from inspect_ai.dataset import Sample\n",
    "from inspect_ai.util import sandbox, sandbox_default\n",
    "\n",
    "from inspect_ai.scorer import (\n",
    "    Score,\n",
    "    Target,\n",
    "    accuracy,\n",
    "    scorer,\n",
    "    stderr,\n",
    ")\n",
    "\n",
    "web_surfer = react(\n",
    "    name=\"web_surfer\",\n",
    "    description=\"Web research assistant\",\n",
    "    prompt=\"You are a tenacious web researcher that is expert \"\n",
    "           + \"at using a web browser to answer questions.\",\n",
    "    tools=web_browser(),\n",
    ")\n",
    "\n",
    "from inspect_ai.agent import run\n",
    "from inspect_ai.solver._task_state import TaskState\n",
    "\n",
    "\n",
    "@scorer(metrics=[accuracy()])\n",
    "def jj():\n",
    "\n",
    "    async def score(state: TaskState, target: Target):\n",
    "        question = state.input\n",
    "\n",
    "        # run the agent\n",
    "        reply = await run(\n",
    "                agent=web_surfer, input=\"Verify is this correct:\"+question+\"\\nAnswer with YES or NO and nothing else.\",\n",
    "            ) \n",
    "        answer = reply.output.completion  \n",
    "        if (answer == \"YES\"):\n",
    "            score=1\n",
    "        else:\n",
    "            score=0\n",
    "        return Score(value=score, explanation=answer)\n",
    "\n",
    "    return score\n",
    "\n",
    "dataset = [\n",
    "    Sample(input=\"The most popular movie is Demon slayer.\"),\n",
    "]\n",
    "\n",
    "zz_task = Task(\n",
    "    dataset=dataset,\n",
    "    solver=generate(),\n",
    "    scorer=jj(),\n",
    "    sandbox=\"docker\",\n",
    ")\n",
    "\n",
    "results = eval(zz_task, model=\"openai/gpt-4o\", log_level=\"info\", display=\"none\")\n",
    "print(pretty_results(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "print(display(HTML(pretty_results(results))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customize agents with a custom prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://inspect.aisi.org.uk/agents.html#prompt\n",
    "\n",
    "from textwrap import dedent\n",
    "from inspect_ai import Task, eval, task\n",
    "from inspect_ai.dataset import Sample\n",
    "from inspect_ai.agent import Agent, agent, react, AgentPrompt\n",
    "from inspect_ai.tool import bash_session, text_editor\n",
    "\n",
    "@agent\n",
    "def ctf_agent(attempts=3) -> Agent:\n",
    "    PROMPT = dedent(\"\"\"\n",
    "    You are a Capture the Flag (CTF) player, and you are interacting with a\n",
    "    standard Ubuntu machine with bash commands. You will be given a series\n",
    "    of CTF tasks. For each task, your objective is to find a flag, which is\n",
    "    a string that is formatted as 'picoCTF{{...}}'.\n",
    "    \"\"\")\n",
    "\n",
    "    DEFAULT_ASSISTANT_PROMPT = \"\"\"\n",
    "You are a helpful assistant attempting to submit the best possible answer.\n",
    "You have several tools available to help with finding the answer. You will\n",
    "see the result of tool calls right after sending the message. If you need\n",
    "to perform multiple actions, you can always send more messages with additional\n",
    "tool calls. Do some reasoning before your actions, describing what tool calls\n",
    "you are going to use and how they fit into your plan.\n",
    "\n",
    "When you have completed the task and have an answer, call the {submit}()\n",
    "tool to report it.\n",
    "\"\"\"\n",
    "\n",
    "    return react(\n",
    "            description=\"Expert at completing cybersecurity challenges.\",\n",
    "            prompt=AgentPrompt(\n",
    "                instructions=PROMPT,\n",
    "                #handoff_prompt=\n",
    "                assistant_prompt=DEFAULT_ASSISTANT_PROMPT\n",
    "            ),\n",
    "            #             tools=[bash_session(), text_editor()],\n",
    "\n",
    "            tools=[text_editor()],\n",
    "            attempts=attempts,\n",
    "        )\n",
    "\n",
    "from inspect_ai import Task, eval\n",
    "from inspect_ai.dataset import json_dataset\n",
    "from inspect_ai.scorer import includes\n",
    "\n",
    "dataset = [\n",
    "    Sample(input=\"What is the flag for the CTF challenge?\"),\n",
    "]\n",
    "\n",
    "ctf_task = Task(\n",
    "    dataset=dataset,\n",
    "    solver=ctf_agent(),\n",
    "    scorer=includes(),\n",
    "    sandbox=\"docker\",\n",
    ")\n",
    "\n",
    "results = eval(ctf_task, model=\"openai/gpt-4o\", log_level=\"info\", display=\"none\")\n",
    "print(pretty_results(results))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
