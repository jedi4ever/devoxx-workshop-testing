{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solvers\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q openai anthropic ipywidgets colorama\n",
    "import os\n",
    "os.environ['XDG_RUNTIME_DIR'] = \"/tmp\"\n",
    "\n",
    "from helpers.reporter.pretty import pretty_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your first solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Typically you build a test `dataset` with test cases.\n",
    "- Each entry in a dataset isis called a `Sample`\n",
    "- A test is called a `Task` : we run `Tasks` on all our `Samples`\n",
    "\n",
    "- A task consists of taking a Sample and first running it through a `solver`.\n",
    "- A `solver` takes the input of the `Sample` and runs this.\n",
    "- The simple solver `generate` send this input to an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c03590ea3a408e8f7c1c09352fb3a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/workspaces/workshop-testing/lessons/04-testing/logs/2025-05-08T06-59-46+00-00_simple-generate_PM3gb6H3VthKQAcakzoHSS.eval\">/workspaces/workshop-testing/lessons/04-testing/logs/2025-05-08T06-59-46+00-00_simple-generate_PM3gb6H3VthKQAcakzoHSS.eval</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: success Model: openai/gpt-4o-mini\n",
      "======= Sample Begin =================================================================\n",
      "input : Generate a javascript file name hello-world.js that prints out hello\n",
      "target: \n",
      "======================================================================================\n",
      "\u001b[33m user       \u001b[39m> Generate a javascript file name hello-world.js that prints out hello\n",
      "\u001b[33m assistant  \u001b[39m> Sure! Hereâ€™s a simple JavaScript code that prints \"Hello, World!\" to the console. You can name the file `hello-world.js`.\n",
      "\n",
      "```javascript\n",
      "// hello-world.js\n",
      "console.log(\"Hello, World!\");\n",
      "```\n",
      "\n",
      "To create the file:\n",
      "\n",
      "1. Open a text editor of your choice.\n",
      "2. Copy the code above.\n",
      "3. Save the file with the name `hello-world.js`.\n",
      "\n",
      "You can run this JavaScript file using Node.js by executing the following command in your terminal:\n",
      "\n",
      "```bash\n",
      "node hello-world.js\n",
      "```\n",
      "\n",
      "This will output:\n",
      "\n",
      "```\n",
      "Hello, World!\n",
      "```\n",
      "======== Score =======================================================================\n",
      "======================================================================================\n",
      "**** End Sample ******************************************************************\n"
     ]
    }
   ],
   "source": [
    "from inspect_ai import Task, task, eval\n",
    "from inspect_ai.dataset import Sample\n",
    "from inspect_ai.solver import generate\n",
    "\n",
    "@task\n",
    "def simple_generate() -> Task:\n",
    "\n",
    "    dataset=[\n",
    "        Sample(\n",
    "            input=\"Generate a javascript file name hello-world.js that prints out hello\"\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    return Task(dataset=dataset,\n",
    "        solver=[\n",
    "            generate(model = \"openai/gpt-4o-mini\",)\n",
    "        ],\n",
    "    )\n",
    "\n",
    "# We set the display to none, as we do our own reporting\n",
    "results = eval(simple_generate, log_level=\"info\",display=\"none\")\n",
    "print(pretty_results(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set default model\n",
    "Instead of specifying a model every time, we set the default mode via an environment variable `INSPECT_EVAL_MODEL`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b7727c16d9c4040845f41c507abb081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/workspaces/workshop-testing/lessons/04-testing/logs/2025-05-08T06-59-50+00-00_simple-generate_PoeYqEzQejZsu7ihDyfmFf.eval\">/workspaces/workshop-testing/lessons/04-testing/logs/2025-05-08T06-59-50+00-00_simple-generate_PoeYqEzQejZsu7ihDyfmFf.eval</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: success Model: openai/gpt-4o-mini\n",
      "======= Sample Begin =================================================================\n",
      "input : Generate a javascript file name hello-world.js that prints out hello\n",
      "target: \n",
      "======================================================================================\n",
      "\u001b[33m user       \u001b[39m> Generate a javascript file name hello-world.js that prints out hello\n",
      "\u001b[33m assistant  \u001b[39m> Certainly! Below is a simple JavaScript code snippet that will print \"Hello\" to the console. You can create a file named `hello-world.js` and include the following code:\n",
      "\n",
      "```javascript\n",
      "// hello-world.js\n",
      "console.log(\"Hello\");\n",
      "```\n",
      "\n",
      "To create the file, follow these steps:\n",
      "\n",
      "1. Open your text editor or Integrated Development Environment (IDE).\n",
      "2. Create a new file and name it `hello-world.js`.\n",
      "3. Copy the code above into the file.\n",
      "4. Save the file.\n",
      "\n",
      "To run the script, you can use Node.js. Open your terminal or command prompt and navigate to the directory where the `hello-world.js` file is located. Run the following command:\n",
      "\n",
      "```bash\n",
      "node hello-world.js\n",
      "```\n",
      "\n",
      "This will print \"Hello\" to the console.\n",
      "======== Score =======================================================================\n",
      "======================================================================================\n",
      "**** End Sample ******************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Set default model to gpt-4o-mini\n",
    "os.environ['INSPECT_EVAL_MODEL'] = \"openai/gpt-4o-mini\"\n",
    "\n",
    "from inspect_ai import Task, task, eval\n",
    "from inspect_ai.dataset import Sample\n",
    "from inspect_ai.solver import generate\n",
    "\n",
    "@task\n",
    "def simple_generate() -> Task:\n",
    "\n",
    "    dataset=[\n",
    "        Sample(\n",
    "            input=\"Generate a javascript file name hello-world.js that prints out hello\"\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    return Task(dataset=dataset,\n",
    "        solver=[\n",
    "            generate()\n",
    "        ],\n",
    "    )\n",
    "\n",
    "results = eval(simple_generate,log_level=\"info\",display=\"none\")\n",
    "print(pretty_results(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running multiple models\n",
    "- We can also set the model we want to use in the evaluation run itself.\n",
    "- This allows use to run the same Task on different models without changing the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac949cd5b4884e2881faf91893d442ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/workspaces/workshop-testing/lessons/04-testing/logs/2025-05-08T06-59-53+00-00_simple-generate_fmsMCzv4K5ZB7vN6FSNsyW.eval\">/workspaces/workshop-testing/lessons/04-testing/logs/2025-05-08T06-59-53+00-00_simple-generate_fmsMCzv4K5ZB7vN6FSNsyW.eval</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: success Model: openai/gpt-4o-mini\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/workspaces/workshop-testing/lessons/04-testing/logs/2025-05-08T06-59-53+00-00_simple-generate_gVk3KNcxkiiy4oDzs3kk5n.eval\">/workspaces/workshop-testing/lessons/04-testing/logs/2025-05-08T06-59-53+00-00_simple-generate_gVk3KNcxkiiy4oDzs3kk5n.eval</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: success Model: openai/gpt-4o\n",
      "======= Sample Begin =================================================================\n",
      "input : Generate a javascript file name hello-world.js that prints out hello\n",
      "target: \n",
      "======================================================================================\n",
      "\u001b[33m user       \u001b[39m> Generate a javascript file name hello-world.js that prints out hello\n",
      "\u001b[33m assistant  \u001b[39m> You can create a simple JavaScript file named `hello-world.js` that prints \"hello\" to the console. Below is the content you should include in that file:\n",
      "\n",
      "```javascript\n",
      "// hello-world.js\n",
      "console.log(\"hello\");\n",
      "```\n",
      "\n",
      "### Steps to Create the File:\n",
      "1. Open a text editor or an integrated development environment (IDE) of your choice.\n",
      "2. Copy the code above.\n",
      "3. Save the file with the name `hello-world.js`.\n",
      "\n",
      "### Running the JavaScript File:\n",
      "To run the script, you can use Node.js if you have it installed. Open your terminal or command prompt, navigate to the directory where your `hello-world.js` file is located, and run the following command:\n",
      "\n",
      "```bash\n",
      "node hello-world.js\n",
      "```\n",
      "\n",
      "This will execute the script, and you should see \"hello\" printed in the terminal.\n",
      "======== Score =======================================================================\n",
      "======================================================================================\n",
      "**** End Sample ******************************************************************\n",
      "======= Sample Begin =================================================================\n",
      "input : Generate a javascript file name hello-world.js that prints out hello\n",
      "target: \n",
      "======================================================================================\n",
      "\u001b[33m user       \u001b[39m> Generate a javascript file name hello-world.js that prints out hello\n",
      "\u001b[33m assistant  \u001b[39m> Certainly! Below is the content for a simple JavaScript file named `hello-world.js` that prints \"Hello\" to the console:\n",
      "\n",
      "```javascript\n",
      "// hello-world.js\n",
      "\n",
      "console.log(\"Hello\");\n",
      "```\n",
      "\n",
      "To use this script, you can create a file named `hello-world.js` and paste the code above into it. Then, you can run the script using Node.js by running the following command in your terminal or command prompt:\n",
      "\n",
      "```bash\n",
      "node hello-world.js\n",
      "```\n",
      "\n",
      "This will execute the JavaScript file and print \"Hello\" to the console.\n",
      "======== Score =======================================================================\n",
      "======================================================================================\n",
      "**** End Sample ******************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Set default model to gpt-4o-mini\n",
    "os.environ['INSPECT_EVAL_MODEL'] = \"openai/gpt-4o-mini\"\n",
    "\n",
    "from inspect_ai import Task, task, eval\n",
    "from inspect_ai.dataset import Sample\n",
    "from inspect_ai.solver import generate\n",
    "\n",
    "@task\n",
    "def simple_generate() -> Task:\n",
    "\n",
    "    dataset=[\n",
    "        Sample(\n",
    "            input=\"Generate a javascript file name hello-world.js that prints out hello\"\n",
    "        )\n",
    "    ]\n",
    "\n",
    "\n",
    "    return Task(dataset=dataset,\n",
    "        solver=[\n",
    "            generate()\n",
    "        ],\n",
    "    )\n",
    "\n",
    "models = [\n",
    "    \"openai/gpt-4o-mini\",\n",
    "    \"openai/gpt-4o\",\n",
    "]\n",
    "results = eval(simple_generate,log_level=\"info\", model = models, display=\"none\")\n",
    "print(pretty_results(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a system prompt\n",
    "- As part of our test, we can also specify a system prompt.\n",
    "- That gets passed to the generate() before sending it off to the LLM.\n",
    "- The command `system_prompt` will either take a string, or if it's a filename try to read that file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5287fe93796749b485a1adea4bbc0bd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/workspaces/workshop-testing/lessons/04-testing/logs/2025-05-08T06-59-56+00-00_system-message-solver_nehUHgDTL9LUJSRqV9Fv7j.eval\">/workspaces/workshop-testing/lessons/04-testing/logs/2025-05-08T06-59-56+00-00_system-message-solver_nehUHgDTL9LUJSRqV9Fv7j.eval</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: success Model: openai/gpt-4o-mini\n",
      "======= Sample Begin =================================================================\n",
      "input : Generate a javascript file name hello-world.js that prints out hello\n",
      "target: \n",
      "======================================================================================\n",
      "\u001b[33m system     \u001b[39m> You are a code generation assistant. Your task is to generate code based on the input provided.\n",
      "    You should ensure that the generated code meets the requirements specified in the input.\n",
      "    You should also ensure that the generated code is syntactically correct and can be executed without errors.\n",
      "    Make sure to output the code and not any additional text or comments.\n",
      "\n",
      "\u001b[33m user       \u001b[39m> Generate a javascript file name hello-world.js that prints out hello\n",
      "\u001b[33m assistant  \u001b[39m> ```javascript\n",
      "// hello-world.js\n",
      "console.log('hello');\n",
      "```\n",
      "======== Score =======================================================================\n",
      "======================================================================================\n",
      "**** End Sample ******************************************************************\n"
     ]
    }
   ],
   "source": [
    "from inspect_ai import Task, task, eval\n",
    "from inspect_ai.dataset import Sample\n",
    "from inspect_ai.solver import system_message, generate\n",
    "from textwrap import dedent\n",
    "\n",
    "@task\n",
    "def system_message_solver() -> Task:\n",
    "\n",
    "    dataset=[\n",
    "        Sample(\n",
    "            input=\"Generate a javascript file name hello-world.js that prints out hello\"\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    SYSTEM_PROMPT = \"\"\"You are a code generation assistant. Your task is to generate code based on the input provided.\n",
    "    You should ensure that the generated code meets the requirements specified in the input.\n",
    "    You should also ensure that the generated code is syntactically correct and can be executed without errors.\n",
    "    Make sure to output the code and not any additional text or comments.\n",
    "    \"\"\"\n",
    "    \n",
    "    return Task(dataset=dataset,\n",
    "        solver=[\n",
    "            system_message(dedent(SYSTEM_PROMPT)),\n",
    "            generate()\n",
    "        ],\n",
    "    )\n",
    "\n",
    "results = eval(system_message_solver,log_level=\"info\",display=\"none\")\n",
    "print(pretty_results(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic picture\n",
    "- Input in Samples is not limited to just text, we can send images too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9254429de74043c7a4dbbefba7dd9d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/workspaces/workshop-testing/lessons/04-testing/logs/2025-05-08T06-59-58+00-00_picture-basic_5NqhqSxyvcd3tjEh3Vixa3.eval\">/workspaces/workshop-testing/lessons/04-testing/logs/2025-05-08T06-59-58+00-00_picture-basic_5NqhqSxyvcd3tjEh3Vixa3.eval</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: success Model: openai/gpt-4o-mini\n",
      "======= Sample Begin =================================================================\n",
      "input : [ChatMessageUser(id='VRbGB9yMVhXu8xwi3s9xqZ', content=[ContentText(type='text', text='(Image)', refusal=None), ContentText(type='text', text='What is this a picture of?', refusal=None)], source=None, internal=None, role='user', tool_call_id=None)]\n",
      "target: \n",
      "======================================================================================\n",
      "\n",
      "\u001b[33m user       \u001b[39m+> What is this a picture of?\n",
      "\u001b[33m assistant  \u001b[39m> This is a screenshot of the Uber website, showcasing the interface for booking a ride. It includes fields for entering pickup and drop-off locations, options for selecting the date and time, and a map displayed on the right side. There's also a cookie consent notification at the bottom.\n",
      "======== Score =======================================================================\n",
      "======================================================================================\n",
      "**** End Sample ******************************************************************\n"
     ]
    }
   ],
   "source": [
    "from inspect_ai import Task, task, eval\n",
    "from inspect_ai.dataset import Sample\n",
    "from inspect_ai.model import ChatMessageUser, ContentImage, ContentText\n",
    "from inspect_ai.solver import system_message, generate\n",
    "from inspect_ai.scorer import includes, model_graded_fact\n",
    "\n",
    "@task\n",
    "def picture_basic():\n",
    "    dataset = [\n",
    "        Sample(input = [\n",
    "            ChatMessageUser(content = [\n",
    "                ContentImage(image=\"data/screenshot.png\"),\n",
    "                ContentText(text=\"What is this a picture of?\")\n",
    "            ])\n",
    "        ])\n",
    "    ]\n",
    "\n",
    "    task = Task(\n",
    "        dataset=dataset,\n",
    "        solver=generate(),\n",
    "    )\n",
    "    return task\n",
    "\n",
    "\n",
    "results = eval(picture_basic,log_level=\"info\",display=\"none\")\n",
    "print(pretty_results(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom solver\n",
    "- It's easy to build your own solver.\n",
    "- <https://inspect.aisi.org.uk/solvers.html#custom-solvers>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97e9843999e487abcac53d26d075c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/workspaces/workshop-testing/lessons/04-testing/logs/2025-05-08T07-11-09+00-00_code-solver_92w4h4nvBNqCzuB98H7smD.eval\">/workspaces/workshop-testing/lessons/04-testing/logs/2025-05-08T07-11-09+00-00_code-solver_92w4h4nvBNqCzuB98H7smD.eval</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: success Model: openai/gpt-4o-mini\n",
      "======= Sample Begin =================================================================\n",
      "input : a function that prints out hello\n",
      "target: \n",
      "======================================================================================\n",
      "\u001b[33m user       \u001b[39m> a function that prints out hello\n",
      "\u001b[33m assistant  \u001b[39m> ```java\n",
      "public class HelloWorld {\n",
      "    public static void main(String[] args) {\n",
      "        printHello();\n",
      "    }\n",
      "\n",
      "    public static void printHello() {\n",
      "        System.out.println(\"Hello\");\n",
      "    }\n",
      "}\n",
      "```\n",
      "======== Score =======================================================================\n",
      "======================================================================================\n",
      "**** End Sample ******************************************************************\n"
     ]
    }
   ],
   "source": [
    "from inspect_ai.scorer import Target\n",
    "from inspect_ai.solver import (solver, Solver, Generate)\n",
    "from inspect_ai.solver._task_state import TaskState\n",
    "from inspect_ai.model import Model,get_model\n",
    "from inspect_ai.util import resource\n",
    "from inspect_ai.model import ChatMessageAssistant\n",
    "\n",
    "\n",
    "CODE_TEMPLATE = \"Generate java code that does the following: {question}. Onky output the code, do not add any comments or explanations.\"\n",
    "\n",
    "@solver\n",
    "def code_generator(\n",
    "    model: str | Model | None = None,\n",
    "):\n",
    "\n",
    "    # resolve model\n",
    "    model = get_model(model)\n",
    "\n",
    "    # here is wheree the logic happens\n",
    "    async def solve(state: TaskState, generate: Generate) -> TaskState:\n",
    "        # run generation\n",
    "        response = await model.generate(\n",
    "            CODE_TEMPLATE.format(\n",
    "                question=state.input_text\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # add the critique as a user message\n",
    "        state.messages.append(\n",
    "            ChatMessageAssistant(\n",
    "                content=response.completion,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # regenerate\n",
    "        return state\n",
    "\n",
    "    return solve\n",
    "\n",
    "@task\n",
    "def code_solver() -> Task:\n",
    "    dataset = [\n",
    "        Sample(\n",
    "            input=\"a function that prints out hello\"\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    return Task(\n",
    "        dataset=dataset,\n",
    "        solver=code_generator(model=\"openai/gpt-4o-mini\"),\n",
    "    )\n",
    "\n",
    "\n",
    "results = eval(code_solver,log_level=\"info\",display=\"none\")\n",
    "print(pretty_results(results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
