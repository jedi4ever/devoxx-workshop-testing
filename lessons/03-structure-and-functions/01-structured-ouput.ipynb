{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured output\n",
    "## Introduction\n",
    "- In applications we often want the llm to return structured output according to a schema.\n",
    "- We can ask it to return a json, but this might not be what we want.\n",
    "- In this lesson we'll show how to use Pydantic to define the schema and have the LLM return a structured output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langchain langchain-openai pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a simple question and ask it to return it as json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize the language model\n",
    "llm_model = \"gpt-4o-mini\"\n",
    "llm = ChatOpenAI(temperature=0, model=llm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ask it to return a json with the fields firstname, lastname, title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"firstname\": \"Patrick\",\n",
      "  \"lastname\": \"Debois\",\n",
      "  \"title\": \"genAI expert\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "question = \"My name is Patrick Debois. I am a genAI expert. Please return this information as a json using the fields firstname, lastname, title\"\n",
    "result = llm.invoke(question)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that it actually doesn't return a json, but a Markdown formatted json block.\n",
    "\n",
    "Now we ask it a bit more complicated by turning it into an array of people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the information formatted as a JSON object with an array of people:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"people\": [\n",
      "    {\n",
      "      \"firstname\": \"Patrick\",\n",
      "      \"lastname\": \"Debois\",\n",
      "      \"title\": \"genAI expert\",\n",
      "      \"number_of_eyes\": 2\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "question = \"My name is Patrick Debois. I am a genAI expert. I got two eyes. Please return this information as a json with an Array of people using the fields firstname, lastname, title and number of eyes.\"\n",
    "result = llm.invoke(question)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pydantic Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the experience  we will use the `pydantic` library to define an object with schema checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field, validator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Object properties using a schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a basic Person object with firstname ,  lastname as well as age.\n",
    "\n",
    "You can see that we can specify the type of age indicating we want it as an integer and not a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your desired data structure.\n",
    "class Person(BaseModel):\n",
    "    firstname: str = Field(description=\"person first name\")\n",
    "    lastname: str = Field(description=\"person last name\")\n",
    "    age: int = Field(description=\"person age\")\n",
    "    eyes: int = Field(description=\"eyes count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning a Pydantic in a Parser\n",
    "To use the schema, we take the object definition and turn this into a Langchain Pydantic parser.\n",
    "The parser can then be used to return the instructions it would pass to the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"firstname\": {\"description\": \"person first name\", \"title\": \"Firstname\", \"type\": \"string\"}, \"lastname\": {\"description\": \"person last name\", \"title\": \"Lastname\", \"type\": \"string\"}, \"age\": {\"description\": \"person age\", \"title\": \"Age\", \"type\": \"integer\"}, \"eyes\": {\"description\": \"eyes count\", \"title\": \"Eyes\", \"type\": \"integer\"}}, \"required\": [\"firstname\", \"lastname\", \"age\", \"eyes\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Set up a parser + inject instructions into the prompt template.\n",
    "person_parser = PydanticOutputParser(pydantic_object=Person)\n",
    "print(person_parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the instructions can now be passed to the LLM using a system prompt for example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the instructions to the prompt\n",
    "Now that we have instructions, adding them to the prompt template is easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"firstname\": \"Patrick\",\n",
      "  \"lastname\": \"Debois\",\n",
      "  \"age\": 55,\n",
      "  \"eyes\": 2\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "name_query = \"My name is Patrick Debois. I'm 55 year's old. I got two eyes. What is my first name, last name , age and number of eyes ?\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": person_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "prompt = prompt_template.format(query=name_query)\n",
    "answer = llm.invoke(prompt)\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example adapted from <https://python.langchain.com/v0.1/docs/modules/model_io/output_parsers/types/pydantic/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A List of things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can do the same with our list of People example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"$defs\": {\"Person\": {\"properties\": {\"firstname\": {\"description\": \"person first name\", \"title\": \"Firstname\", \"type\": \"string\"}, \"lastname\": {\"description\": \"person last name\", \"title\": \"Lastname\", \"type\": \"string\"}, \"age\": {\"description\": \"person age\", \"title\": \"Age\", \"type\": \"integer\"}, \"eyes\": {\"description\": \"eyes count\", \"title\": \"Eyes\", \"type\": \"integer\"}}, \"required\": [\"firstname\", \"lastname\", \"age\", \"eyes\"], \"title\": \"Person\", \"type\": \"object\"}}, \"properties\": {\"friends\": {\"description\": \"a list of persons\", \"items\": {\"$ref\": \"#/$defs/Person\"}, \"title\": \"Friends\", \"type\": \"array\"}}, \"required\": [\"friends\"]}\n",
      "```\n",
      "======== the json ==========\n",
      "```json\n",
      "{\n",
      "  \"friends\": [\n",
      "    {\n",
      "      \"firstname\": \"Patrick\",\n",
      "      \"lastname\": \"Debois\",\n",
      "      \"age\": 55,\n",
      "      \"eyes\": 2\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "class People(BaseModel):\n",
    "    friends: List[Person] = Field(description=\"a list of persons\")\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "people_parser = PydanticOutputParser(pydantic_object=People)\n",
    "print(people_parser.get_format_instructions())\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "name_query = \"My name is Patrick Debois. I'm 55 year's old. What is do you know about me ?\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": people_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "prompt = prompt_template.format(query=name_query)\n",
    "answer = llm.invoke(prompt)\n",
    "\n",
    "print(\"======== the json ==========\")\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we can use the parser to parse the answer and get an Object back.\n",
    "- No need to extract the json from the markdown ourselves, the parser does this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "friends=[Person(firstname='Patrick', lastname='Debois', age=55, eyes=2)]\n"
     ]
    }
   ],
   "source": [
    "people = people_parser.parse(answer.content)\n",
    "print(people)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
