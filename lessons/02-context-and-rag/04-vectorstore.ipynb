{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorstore\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can also index documentation similar to code.\n",
    "- In it's simplest form, a vector database is a datastore that allows us to find similar and related documents.\n",
    "- It is similar to a search engine, but instead of searching for a string or keyworkd, we use the concept of embeddings.\n",
    "- We'll be using Chroma as popular vector database.\n",
    "- Many other vector databases exist and now more and more traditional databases are adding vector search capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HNSWLIB_NO_NATIVE\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain langchain-openai langchain-community tiktoken chromadb langchain-chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In Langchain we can present documents in a structured way using the Document object.\n",
    "- We have a text and metadata field.\n",
    "- Let's convert some information into this format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the texts\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "data = [\n",
    "    {\n",
    "        \"text\": \"We use REST API to communicate with the server.\",\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"For testing in javascript we use Jest.\" \n",
    "    }, \n",
    "    {\n",
    "        \"text\": \"We prefer snake_case for naming variables over CamelCase in javascript.\",\n",
    "    }\n",
    "]\n",
    "\n",
    "documents = []\n",
    "\n",
    "for item in data:\n",
    "    document = Document(\n",
    "        page_content=item[\"text\"],\n",
    "    )\n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChromaDB - A vector database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Chromadb has the concept of collections.\n",
    "- A collection is similar to a database or table in a traditional database.\n",
    "- For this example to run, we check first if the collection workshop exists.\n",
    "- And if it does, we delete it , so we can start fresh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting documentation\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "collection_name=\"documentation\"\n",
    "chroma_client = chromadb.PersistentClient(path=\"./chromadb\")\n",
    "collections = chroma_client.list_collections()\n",
    "\n",
    "if \"documentation\" in collections:\n",
    "    print(\"deleting documentation\")\n",
    "    chroma_client.delete_collection(\"documentation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the embeddings model\n",
    "- To index the documents, we need to seelect an embeddings model.\n",
    "- The specific model will be used to calculate the similarity between the documents.\n",
    "- You need to use the same model for indexing and querying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text-embedding-ada-002\n"
     ]
    }
   ],
   "source": [
    "# Set the embeddings function\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "print(embeddings.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populating the vector database\n",
    "- The Vectory database will calculate the embedding for each document.\n",
    "- It will store the text and metadata in the store as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectory database will calculate them using the embeddings_model provided\n",
    "# and store the embeddings for each doc in it's database\n",
    "# from langchain_community.vectorstores import Chroma\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings,\n",
    "    client=chroma_client,\n",
    "    collection_name=collection_name\n",
    "    # client_settings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once stored , we can ask it to find the related documents through embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying for similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We ask the vector database to find the most similar documents to our query.\n",
    "- We can control the number of results we get back. using the k parameter.\n",
    "- We can also control the threshold of relevance. using the score_threshold parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query:  What protocol do we use to communicate with the server ?\n",
      "(Document(id='36b62b03-9371-4e08-8df4-a04dd66d27a5', metadata={}, page_content='We use REST API to communicate with the server.'), 0.8068346522236127)\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query:  What is the testing framework for javascript?\n",
      "(Document(id='9829c334-885a-42da-896a-cc4f0c2ff395', metadata={}, page_content='For testing in javascript we use Jest.'), 0.851067264274354)\n",
      "(Document(id='a48ac426-c3db-4bf3-a435-4a9852573e58', metadata={}, page_content='We prefer snake_case for naming variables over CamelCase in javascript.'), 0.7117564646913745)\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"What protocol do we use to communicate with the server ?\",\n",
    "    \"What is the testing framework for javascript?\",\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    docs = vectorstore.similarity_search_with_relevance_scores(query, k=4, score_threshold=0.7)\n",
    "    print(\"query: \", query)\n",
    "    for doc in docs:\n",
    "        print(doc)\n",
    "    print(\"---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
